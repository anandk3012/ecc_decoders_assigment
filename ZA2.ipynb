{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8642f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import kron\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea8136c",
   "metadata": {},
   "source": [
    "## Build Polar code and code words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ca527df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polar Code Parameters\n",
    "n = 256\n",
    "k = 9\n",
    "p = 0.1\n",
    "Afile = f'A/Polar_A_file_n_{n}_k_{k}.mat'\n",
    "A = loadmat(Afile)['A'].ravel()\n",
    "\n",
    "m = np.log2(n).astype(int)\n",
    "# Kernel\n",
    "F = np.array([[1, 0], [1, 1]])\n",
    "\n",
    "# Generator matrix : G_m\n",
    "G = F\n",
    "for _ in range(2, m + 1):\n",
    "    G = kron(G, F) % 2\n",
    "\n",
    "# Permutation matrix : P_m\n",
    "# P = G[:k, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c9d05bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A/Polar_A_file_n_256_k_9.mat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [i - 1 for i in A]  # Convert to 0 based indexing\n",
    "Afile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48613f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.uint16(247),\n",
       " np.uint16(248),\n",
       " np.uint16(249),\n",
       " np.uint16(250),\n",
       " np.uint16(251),\n",
       " np.uint16(252),\n",
       " np.uint16(253),\n",
       " np.uint16(254),\n",
       " np.uint16(255)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d9a108b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 973474.00it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_codewords(k : int, G : np.ndarray = G, A : np.ndarray = A) -> np.ndarray:\n",
    "    \"\"\" Build Polar code and code words \"\"\"\n",
    "    # All possible messages\n",
    "    messages = np.array([list(np.binary_repr(i, width=k)) for i in tqdm(range(2**k))]).astype(int)\n",
    "    \n",
    "    # Codewords\n",
    "    codewords = (messages @ G[A, :]) % 2\n",
    "\n",
    "    return codewords\n",
    "codewords = get_codewords(k, G, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c436d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 256)\n",
      "(512, 256)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(codewords.shape)\n",
    "print(np.unique(codewords, axis=0).shape)\n",
    "print(np.any(codewords[1:] != 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c51224d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n from G: 256\n",
      "k from A: 9\n",
      "k you used: 9\n",
      "zeros in codewords[0]: True\n"
     ]
    }
   ],
   "source": [
    "print(\"n from G:\", G.shape[1])\n",
    "print(\"k from A:\", len(A))\n",
    "print(\"k you used:\", k)\n",
    "print(\"zeros in codewords[0]:\", (codewords[0] == 0).all())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeb9007",
   "metadata": {},
   "source": [
    "## Get corrupted messages for decoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "072ce1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0 128 ...   8 138   0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 256)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_corrupted_words(filename, n):\n",
    "    buf = np.fromfile(filename, dtype=np.uint8)\n",
    "    total_bits = buf.size * 8\n",
    "    N = total_bits // n\n",
    "    assert total_bits % n == 0, \"Total bits not a multiple of codeword length.\"\n",
    "\n",
    "    print(buf)\n",
    "    # Try MSB-first (common)\n",
    "    bits_big = np.unpackbits(buf, bitorder='big')  # shape (N*n,1)\n",
    "    Y_big = bits_big.reshape(N, n)                 # (N, n)\n",
    "\n",
    "    # Optionally also prepare LSB-first to test if needed:\n",
    "    bits_little = np.unpackbits(buf, bitorder='little')\n",
    "    Y_little = bits_little.reshape(N, n)\n",
    "\n",
    "    return Y_big, Y_little, N, total_bits\n",
    "\n",
    "corrupted_file_name = f\"n_{n}_k_{k}_p_{p}\"\n",
    "Y_big, Y_little, N, total_bits = load_corrupted_words(f'corrupted_files/{corrupted_file_name}.txt', n)\n",
    "Y_big.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5591acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n_256_k_9_p_0.1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f82db5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape: (100, 256)\n",
      "unique Y rows: (100, 256)\n",
      "row sums sample: [27 32 35 21 34 24 20 19 27 27]\n"
     ]
    }
   ],
   "source": [
    "Y = Y_big  # Choose big-endian version for decoding\n",
    "print(\"Y shape:\", Y.shape)\n",
    "print(\"unique Y rows:\", np.unique(Y, axis=0).shape)\n",
    "print(\"row sums sample:\", Y[:10].sum(axis=1))  # how many 1s per row?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e954e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min dist: 27 argmin: 0\n",
      "five smallest: [  0 170 128 160 240] [27 47 51 51 53]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "y = Y[i].ravel().astype(np.uint8) % 2\n",
    "d = np.sum(codewords != y, axis=1)\n",
    "print(\"min dist:\", d.min(), \"argmin:\", d.argmin())\n",
    "print(\"five smallest:\", np.argsort(d)[:5], d[np.argsort(d)[:5]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059f69b1",
   "metadata": {},
   "source": [
    "## ML Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f76d8b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = \"ml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34e4e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PolarMLDecoder(Y:np.ndarray, codewords:np.ndarray) -> np.ndarray:\n",
    "    \"\"\" \n",
    "    Polar ML Decoder \n",
    "    Y -> Received words (N x n)\n",
    "    codewords -> All possible codewords (2^k x n)\n",
    "    Returns -> Decoded message indices (N,)\n",
    "    \"\"\"\n",
    "    N = Y.shape[0]\n",
    "    decoded_indices = []\n",
    "    dist = []\n",
    "    for i in range(N):\n",
    "        y = Y[i, :]\n",
    "        # Compute Hamming distances to all codewords\n",
    "        distances = np.sum(codewords != y, axis=1)\n",
    "        dist.append(distances)\n",
    "        # Find the index of the minimum distance\n",
    "        min_index = np.argmin(distances)\n",
    "        # Append the corresponding message\n",
    "        decoded_indices.append(min_index)\n",
    "\n",
    "    return np.array(decoded_indices), np.array(dist)\n",
    "\n",
    "decoded_indices, dist = PolarMLDecoder(Y_big, codewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "babc8771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(dist[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f37d3e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000000000', '000000000', '000000000', '000000000', '000000000', '000000000', '000000000', '000000000', '000000000', '000000000']\n"
     ]
    }
   ],
   "source": [
    "decoded_bitstrings = []\n",
    "for idx in decoded_indices:\n",
    "    msg_bits = np.array(list(np.binary_repr(idx, width=k))).astype(int)\n",
    "    decoded_bitstrings.append(''.join(map(str, msg_bits)))\n",
    "\n",
    "print(decoded_bitstrings[15:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5019510",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_message_bits = np.array([[int(c) for c in s] for s in decoded_bitstrings], dtype=np.uint8).flatten()\n",
    "\n",
    "# Add padding\n",
    "padding_length = (8 - (decoded_message_bits.size % 8)) % 8\n",
    "padded_bits = np.concatenate([decoded_message_bits, np.zeros(padding_length, dtype=np.uint8)])\n",
    "\n",
    "# Convert bits to bytes\n",
    "decoded_bytes = np.packbits(padded_bits, bitorder='big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27eba11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write ML Decoder output to file\n",
    "decoded_file_name = corrupted_file_name + \"_out_\" + decoder\n",
    "with open(f'decoded_files/Polar_decoded_{decoded_file_name}.txt', 'w') as f:\n",
    "    for byte in decoded_bytes:\n",
    "        f.write(f\"{byte} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897702b",
   "metadata": {},
   "source": [
    "\n",
    "## Majority Logic Decoding of RM Codes\n",
    "\n",
    "A key advantage of Reed-Muller codes is their amenability to an efficient, iterative decoding method known as majority logic decoding. This procedure systematically recovers the coefficients of the original message polynomial, starting from the highest degree and working downwards. For an $RM(r, m)$ code, this algorithm can correct up to $t = \\lfloor (d_{min}-1)/2 \\rfloor$ errors, where the minimum distance $d_{min}$ is $2^{m-r}$.\n",
    "\n",
    "Throughout this section, we will use the $RM(2, 4)$ code as our running example.\n",
    "\n",
    "*   **Parameters:** $m=4, r=2$.\n",
    "*   **Minimum Distance:** $d_{min} = 2^{4-2} = 4$.\n",
    "*   **Error Correction Capability:** $t = \\lfloor (4-1)/2 \\rfloor = 1$. The decoder can reliably correct any single-bit error in the received vector.\n",
    "\n",
    "### 1. Finding High-Degree Coefficients in a Noiseless Codeword\n",
    "\n",
    "The decoding process begins by isolating the coefficients of the monomials with the highest degree, $r$. In a noiseless setting, this can be done with a simple summation. The key idea is to sum specific bits of the codeword in a way that cancels out the influence of all lower-degree monomials.\n",
    "\n",
    "First, let's define the tools we need:\n",
    "\n",
    "*   **Monomial Index Set ($S$):** For a monomial $M = \\prod_{i \\in S} X_i$, the set $S$ contains the indices of the variables present in that monomial. For the monomial $M = X_1X_2$, the index set is $S=\\{1,2\\}$. The set of uninvolved variable indices is its complement, $S^c=\\{3,4\\}$.\n",
    "\n",
    "*   **Check Set ($\\mathcal{V}_S(\\mathbf{b})$):** A check set for the coefficient $a_S$ is a collection of codeword coordinates. It is defined by fixing the values of the uninvolved variables (those with indices in $S^c$) to a constant binary vector $\\mathbf{b}$.\n",
    "    $$ \\mathcal{V}_S(\\mathbf{b}) = \\{ \\mathbf{v} \\in \\mathbb{F}_2^m \\mid \\text{the components of } \\mathbf{v} \\text{ corresponding to indices in } S^c \\text{ are equal to } \\mathbf{b} \\} $$\n",
    "\n",
    "When we sum the evaluations of a polynomial $f(\\mathbf{X})$ over a check set, a fundamental property of Boolean algebra ensures that any monomial with degree less than the size of the set (here, degree $< r$) will evaluate to one an even number of times. Thus, its sum is zero in $\\mathbb{F}_2$. The only term that may have a non-zero sum is the highest-degree monomial matching the variables of the check set. This allows us to isolate its coefficient.\n",
    "\n",
    "#### Example: Finding $a_{12}$ in a Noiseless $RM(2,4)$ Codeword\n",
    "\n",
    "Let the message polynomial be $f(\\mathbf{X}) = X_1X_2 + X_3$. Its noiseless codeword is:\n",
    "$\\mathbf{C} = (0,0,1,1, \\ 0,0,1,1, \\ 0,0,1,1, \\ 1,1,0,0)$\n",
    "\n",
    "To find the coefficient $a_{12}$, we can use any check set for this monomial. Let's choose the one where the uninvolved variables $(X_3, X_4)$ are fixed to $\\mathbf{b}=(0,0)$. The check set is $\\mathcal{V}_{12}(0,0) = \\{(0000), (0100), (1000), (1100)\\}$. The check sum is:\n",
    "$$ \\text{Sum} = C_{(0000)} + C_{(0100)} + C_{(1000)} + C_{(1100)} = 0 + 0 + 0 + 1 = 1 $$\n",
    "This sum directly gives us the coefficient: $a_{12}=1$.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Decoding High-Degree Coefficients from a Noisy Codeword\n",
    "\n",
    "When the received vector $\\mathbf{Y}$ contains errors, a single check sum can be misleading. Majority logic overcomes this by using multiple, disjoint check sets to vote on the correct coefficient value. For a monomial of degree $r$, we can generate $2^{m-r}$ disjoint check sets. For an $RM(r,m)$ code with minimum distance $d_{min}=2^{m-r}$, if the number of errors is at most $t = (d_{min}-1)/2$, a majority of the check sums will still yield the correct value.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. The General Iterative Decoding Algorithm\n",
    "\n",
    "The full decoding algorithm is an iterative process that decodes coefficients in stages, from the highest degree $r$ down to 0. It uses a \"decode and peel\" strategy.\n",
    "\n",
    "**Input:** A received vector $\\mathbf{Y}$ of length $n = 2^m$.\n",
    "**Output:** The decoded message polynomial $\\hat{f}(\\mathbf{X})$.\n",
    "\n",
    "**Initialization:**\n",
    "1.  Set the current degree to decode: $i = r$.\n",
    "2.  Initialize the working vector: $\\mathbf{Y}_r = \\mathbf{Y}$.\n",
    "3.  Initialize the final decoded polynomial: $\\hat{f}(\\mathbf{X}) = 0$.\n",
    "\n",
    "**Iterative Loop (from $i=r$ down to $0$):**\n",
    "\n",
    "1.  **Decode Coefficients of Degree $i$:**\n",
    "    *   For each of the $\\binom{m}{i}$ monomials $M_S$ of degree $i$:\n",
    "        a. Generate all $2^{m-i}$ disjoint check sets $\\mathcal{V}_S(\\mathbf{b})$ by letting $\\mathbf{b}$ range over all vectors in $\\mathbb{F}_2^{m-i}$.\n",
    "        b. For each check set, compute a check sum (an estimate) by summing the values of the current working vector $\\mathbf{Y}_i$ over the coordinates in that set.\n",
    "        c. Determine the coefficient $\\hat{a}_S$ by taking the majority vote of the $2^{m-i}$ estimates.\n",
    "\n",
    "2.  **Form Degree-$i$ Polynomial:**\n",
    "    *   Construct the polynomial containing all the just-decoded terms of degree $i$:\n",
    "        $$ \\hat{f}_i(\\mathbf{X}) = \\sum_{|S|=i} \\hat{a}_S M_S $$\n",
    "\n",
    "3.  **Update Final Polynomial:**\n",
    "    *   Add this part to the overall result: $\\hat{f}(\\mathbf{X}) = \\hat{f}(\\mathbf{X}) + \\hat{f}_i(\\mathbf{X})$.\n",
    "\n",
    "4.  **\"Peel Off\" and Prepare for Next Stage:**\n",
    "    *   Generate the codeword for the degree-$i$ polynomial: $\\mathbf{C}_i = \\text{Eval}(\\hat{f}_i)$.\n",
    "    *   Create the working vector for the next lower degree by subtracting this contribution (using XOR):\n",
    "        $$ \\mathbf{Y}_{i-1} = \\mathbf{Y}_i + \\mathbf{C}_i $$\n",
    "\n",
    "5.  **Decrement:**\n",
    "    *   Set $i = i - 1$ and repeat the loop until all degrees down to 0 have been processed.\n",
    "\n",
    "---\n",
    "\n",
    "### A Detailed Example: Full Decoding of an RM(2,4) Vector\n",
    "\n",
    "Let's apply the general algorithm to our example. Suppose a single error flips the first bit of the codeword for $f(\\mathbf{X}) = X_1X_2 + X_3$. The received vector is:\n",
    "$\\mathbf{Y} = (\\textbf{1},0,1,1, \\ 0,0,1,1, \\ 0,0,1,1, \\ 1,1,0,0)$\n",
    "\n",
    "#### **Stage 1: Decode Degree 2 (i=2)**\n",
    "We begin with the working vector $\\mathbf{Y}_2 = \\mathbf{Y}$. We decode all $\\binom{4}{2}=6$ degree-2 coefficients.\n",
    "\n",
    "*   **For $\\hat{a}_{12}$ (fix $X_3,X_4$):**\n",
    "    *   $v_3,v_4=0,0$: $Y_{(0000)}+Y_{(0100)}+Y_{(1000)}+Y_{(1100)} = 1+0+0+1=0$.\n",
    "    *   $v_3,v_4=0,1$: $Y_{(0001)}+Y_{(0101)}+Y_{(1001)}+Y_{(1101)} = 0+0+0+1=1$.\n",
    "    *   $v_3,v_4=1,0$: $Y_{(0010)}+Y_{(0110)}+Y_{(1010)}+Y_{(1110)} = 1+1+1+0=1$.\n",
    "    *   $v_3,v_4=1,1$: $Y_{(0011)}+Y_{(0111)}+Y_{(1011)}+Y_{(1111)} = 1+1+1+0=1$.\n",
    "    *   Estimates: $(0,1,1,1) \\implies$ Majority: **1**.\n",
    "*   **For $\\hat{a}_{13}$ (fix $X_2,X_4$):**\n",
    "    *   $v_2,v_4 = 0,0$: $Y_{(0000)}+Y_{(0010)}+Y_{(1000)}+Y_{(1010)} = 1+1+0+1=1$.\n",
    "    *   $v_2,v_4 = 0,1$: $Y_{(0001)}+Y_{(0011)}+Y_{(1001)}+Y_{(1011)} = 0+1+0+1=0$.\n",
    "    *   $v_2,v_4 = 1,0$: $Y_{(0100)}+Y_{(0110)}+Y_{(1100)}+Y_{(1110)} = 0+1+1+0=0$.\n",
    "    *   $v_2,v_4 = 1,1$: $Y_{(0101)}+Y_{(0111)}+Y_{(1101)}+Y_{(1111)} = 0+1+1+0=0$.\n",
    "    *   Estimates: $(1,0,0,0) \\implies$ Majority: **0**.\n",
    "*   **For $\\hat{a}_{14}$ (fix $X_2,X_3$):**\n",
    "    *   $v_2,v_3 = 0,0$: $Y_{(0000)}+Y_{(0001)}+Y_{(1000)}+Y_{(1001)} = 1+0+0+0=1$.\n",
    "    *   $v_2,v_3 = 0,1$: $Y_{(0010)}+Y_{(0011)}+Y_{(1010)}+Y_{(1011)} = 1+1+1+1=0$.\n",
    "    *   $v_2,v_3 = 1,0$: $Y_{(0100)}+Y_{(0101)}+Y_{(1100)}+Y_{(1101)} = 0+0+1+1=0$.\n",
    "    *   $v_2,v_3 = 1,1$: $Y_{(0110)}+Y_{(0111)}+Y_{(1110)}+Y_{(1111)} = 1+1+0+0=0$.\n",
    "    *   Estimates: $(1,0,0,0) \\implies$ Majority: **0**.\n",
    "*   **For $\\hat{a}_{23}$ (fix $X_1,X_4$):**\n",
    "    *   $v_1,v_4 = 0,0$: $Y_{(0000)}+Y_{(0010)}+Y_{(0100)}+Y_{(0110)} = 1+1+0+1=1$.\n",
    "    *   $v_1,v_4 = 0,1$: $Y_{(0001)}+Y_{(0011)}+Y_{(0101)}+Y_{(0111)} = 0+1+0+1=0$.\n",
    "    *   $v_1,v_4 = 1,0$: $Y_{(1000)}+Y_{(1010)}+Y_{(1100)}+Y_{(1110)} = 0+1+1+0=0$.\n",
    "    *   $v_1,v_4 = 1,1$: $Y_{(1001)}+Y_{(1011)}+Y_{(1101)}+Y_{(1111)} = 0+1+1+0=0$.\n",
    "    *   Estimates: $(1,0,0,0) \\implies$ Majority: **0**.\n",
    "*   **For $\\hat{a}_{24}$ (fix $X_1,X_3$):**\n",
    "    *   $v_1,v_3 = 0,0$: $Y_{(0000)}+Y_{(0001)}+Y_{(0100)}+Y_{(0101)} = 1+0+0+0=1$.\n",
    "    *   $v_1,v_3 = 0,1$: $Y_{(0010)}+Y_{(0011)}+Y_{(0110)}+Y_{(0111)} = 1+1+1+1=0$.\n",
    "    *   $v_1,v_3 = 1,0$: $Y_{(1000)}+Y_{(1001)}+Y_{(1100)}+Y_{(1101)} = 0+0+1+1=0$.\n",
    "    *   $v_1,v_3 = 1,1$: $Y_{(1010)}+Y_{(1011)}+Y_{(1110)}+Y_{(1111)} = 1+1+0+0=0$.\n",
    "    *   Estimates: $(1,0,0,0) \\implies$ Majority: **0**.\n",
    "*   **For $\\hat{a}_{34}$ (fix $X_1,X_2$):**\n",
    "    *   $v_1,v_2 = 0,0$: $Y_{(0000)}+Y_{(0001)}+Y_{(0010)}+Y_{(0011)} = 1+0+1+1=1$.\n",
    "    *   $v_1,v_2 = 0,1$: $Y_{(0100)}+Y_{(0101)}+Y_{(0110)}+Y_{(0111)} = 0+0+1+1=0$.\n",
    "    *   $v_1,v_2 = 1,0$: $Y_{(1000)}+Y_{(1001)}+Y_{(1010)}+Y_{(1011)} = 0+0+1+1=0$.\n",
    "    *   $v_1,v_2 = 1,1$: $Y_{(1100)}+Y_{(1101)}+Y_{(1110)}+Y_{(1111)} = 1+1+0+0=0$.\n",
    "    *   Estimates: $(1,0,0,0) \\implies$ Majority: **0**.\n",
    "\n",
    "**Degree-2 Conclusion:** The decoded degree-2 polynomial is $\\hat{f}_2(\\mathbf{X}) = X_1X_2$. Now we peel it off.\n",
    "*   Generate its codeword: $\\mathbf{C}_2 = \\text{Eval}(X_1X_2) = (0,0,0,0, \\ 0,0,0,0, \\ 0,0,0,0, \\ 1,1,1,1)$.\n",
    "*   Update our working vector for the next stage: $\\mathbf{Y}_1 = \\mathbf{Y}_2 + \\mathbf{C}_2 = (1,0,1,1, \\ 0,0,1,1, \\ 0,0,1,1, \\ 0,0,1,1)$.\n",
    "\n",
    "#### **Stage 2: Decode Degree 1 (i=1)**\n",
    "We now use $\\mathbf{Y}_1$ to decode degree-1 coefficients. We are targeting an $RM(1,4)$ code ($d_{min}=8$), so we get 8 estimates for each coefficient.\n",
    "\n",
    "*   **For $\\hat{a}_1$ (fix $X_2,X_3,X_4$):**\n",
    "    *   $v_2,v_3,v_4 = 0,0,0$: $Y'_1{(0000)}+Y'_1{(1000)} = 1+0=1$.\n",
    "    *   $v_2,v_3,v_4 = 0,0,1$: $Y'_1{(0001)}+Y'_1{(1001)} = 0+0=0$.\n",
    "    *   $v_2,v_3,v_4 = 0,1,0$: $Y'_1{(0010)}+Y'_1{(1010)} = 1+1=0$.\n",
    "    *   $v_2,v_3,v_4 = 0,1,1$: $Y'_1{(0011)}+Y'_1{(1011)} = 1+1=0$.\n",
    "    *   $v_2,v_3,v_4 = 1,0,0$: $Y'_1{(0100)}+Y'_1{(1100)} = 0+0=0$.\n",
    "    *   $v_2,v_3,v_4 = 1,0,1$: $Y'_1{(0101)}+Y'_1{(1101)} = 0+0=0$.\n",
    "    *   $v_2,v_3,v_4 = 1,1,0$: $Y'_1{(0110)}+Y'_1{(1110)} = 1+1=0$.\n",
    "    *   $v_2,v_3,v_4 = 1,1,1$: $Y'_1{(0111)}+Y'_1{(1111)} = 1+1=0$.\n",
    "    *   Estimates: $(1,0,0,0,0,0,0,0) \\implies$ Majority: **0**.\n",
    "*   **For $\\hat{a}_2$ (fix $X_1,X_3,X_4$):**\n",
    "    *   $v_1,v_3,v_4 = 0,0,0$: $Y'_1{(0000)}+Y'_1{(0100)} = 1+0=1$.\n",
    "    *   The other 7 sums will be 0.\n",
    "    *   Estimates: $(1,0,0,0,0,0,0,0) \\implies$ Majority: **0**.\n",
    "*   **For $\\hat{a}_3$ (fix $X_1,X_2,X_4$):**\n",
    "    *   $v_1,v_2,v_4 = 0,0,0$: $Y'_1{(0000)}+Y'_1{(0010)} = 1+1=0$.\n",
    "    *   The other 7 sums will be 1.\n",
    "    *   Estimates: $(0,1,1,1,1,1,1,1) \\implies$ Majority: **1**.\n",
    "*   **For $\\hat{a}_4$ (fix $X_1,X_2,X_3$):**\n",
    "    *   $v_1,v_2,v_3 = 0,0,0$: $Y'_1{(0000)}+Y'_1{(0001)} = 1+0=1$.\n",
    "    *   The other 7 sums will be 0.\n",
    "    *   Estimates: $(1,0,0,0,0,0,0,0) \\implies$ Majority: **0**.\n",
    "\n",
    "**Degree-1 Conclusion:** The decoded degree-1 polynomial is $\\hat{f}_1(\\mathbf{X}) = X_3$. We peel it off.\n",
    "*   Generate its codeword: $\\mathbf{C}_1 = \\text{Eval}(X_3) = (0,0,1,1, \\ 0,0,1,1, \\ 0,0,1,1, \\ 0,0,1,1)$.\n",
    "*   Update the vector for the final stage: $\\mathbf{Y}_0 = \\mathbf{Y}_1 + \\mathbf{C}_1 = (1,0,0,0, \\ 0,0,0,0, \\ 0,0,0,0, \\ 0,0,0,0)$.\n",
    "\n",
    "#### **Stage 3: Decode Degree 0 (i=0)**\n",
    "*   To find the constant term $a_0$, we take a majority vote of all 16 bits in $\\mathbf{Y}_0$. There is one '1' and fifteen '0's.\n",
    "*   The majority is **0**, so $\\hat{a}_0=0$. The decoded degree-0 polynomial is $\\hat{f}_0(\\mathbf{X}) = 0$.\n",
    "\n",
    "#### **Final Result:**\n",
    "By summing the polynomials from each stage, we reconstruct the original message:\n",
    "$$ \\hat{f}(\\mathbf{X}) = \\hat{f}_2(\\mathbf{X}) + \\hat{f}_1(\\mathbf{X}) + \\hat{f}_0(\\mathbf{X}) = X_1X_2 + X_3 + 0 = X_1X_2 + X_3 $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
